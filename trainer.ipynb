{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919de98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.color import rgb2gray\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031075d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/kaggle/input/fabric-defect-dataset/Data Set'\n",
    "captured_path = os.path.join(base_path, 'captured')\n",
    "hole_path = os.path.join(base_path, 'hole')\n",
    "horizontal_path = os.path.join(base_path, 'horizontal')\n",
    "vertical_path = os.path.join(base_path, 'verticle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59d0d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            images.append(gray_img)\n",
    "            if 'hole' in folder_path:\n",
    "                labels.append('hole')\n",
    "            elif 'horizontal' in folder_path:\n",
    "                labels.append('horizontal')\n",
    "            elif 'verticle' in folder_path:\n",
    "                labels.append('vertical')\n",
    "            else:\n",
    "                labels.append('unknown')\n",
    "    return images, labels\n",
    "\n",
    "captured_images, captured_labels = load_images_from_folder(captured_path)\n",
    "hole_images, hole_labels = load_images_from_folder(hole_path)\n",
    "horizontal_images, horizontal_labels = load_images_from_folder(horizontal_path)\n",
    "vertical_images, vertical_labels = load_images_from_folder(vertical_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75bbb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 2\n",
    "n_points = 8 * radius\n",
    "\n",
    "def apply_lbp(image):\n",
    "    lbp = local_binary_pattern(image, n_points, radius, method='uniform')\n",
    "    return lbp\n",
    "\n",
    "def apply_lbp_to_images(images):\n",
    "    lbp_images = [apply_lbp(image) for image in images]\n",
    "    return lbp_images\n",
    "\n",
    "lbp_captured_images = apply_lbp_to_images(captured_images)\n",
    "lbp_hole_images = apply_lbp_to_images(hole_images)\n",
    "lbp_horizontal_images = apply_lbp_to_images(horizontal_images)\n",
    "lbp_vertical_images = apply_lbp_to_images(vertical_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70108cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_lbp_histogram(lbp_image, bins=256):\n",
    "    hist, _ = np.histogram(lbp_image.ravel(), bins=np.arange(0, bins + 1), density=True)\n",
    "    return hist\n",
    "\n",
    "def calculate_histograms(lbp_images):\n",
    "    histograms = [calculate_lbp_histogram(lbp) for lbp in lbp_images]\n",
    "    return histograms\n",
    "    \n",
    "histograms_captured = calculate_histograms(lbp_captured_images)\n",
    "histograms_hole = calculate_histograms(lbp_hole_images)\n",
    "histograms_horizontal = calculate_histograms(lbp_horizontal_images)\n",
    "histograms_vertical = calculate_histograms(lbp_vertical_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c93ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(histograms_hole + histograms_horizontal + histograms_vertical)\n",
    "y = np.array(hole_labels + horizontal_labels + vertical_labels)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20022fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "svc = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "splits = {\n",
    "    \"70-30\": 0.3,\n",
    "    \"80-20\": 0.2,\n",
    "    \"90-10\": 0.1\n",
    "}\n",
    "\n",
    "for split_name, test_size in splits.items():\n",
    "    print(f\"\\nEvaluating with {split_name} train-test split\")\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        print(f\"\\nRun {i+1} for {split_name} split\")\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=i)\n",
    "        grid_search = GridSearchCV(svc, param_grid, refit=True, verbose=2, cv=5)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_params = grid_search.best_params_\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        print(f\"Best Parameters found for run {i+1}: {best_params}\")\n",
    "        \n",
    "        model_filename = f'best_fabric_defect_model_{split_name}_run{i+1}.pkl'\n",
    "        joblib.dump(best_model, model_filename)\n",
    "        print(f\"Model saved as {model_filename}\")\n",
    "        \n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        print(f\"Classification report for run {i+1}:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "        accuracies.append(accuracy)\n",
    "        print(f\"Accuracy for run {i+1}: {accuracy:.2f}%\")\n",
    "    \n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    print(f\"\\nAverage Accuracy for {split_name} over 10 runs: {avg_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9bd441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def visualize_lbp(original_images, lbp_images, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    indices = random.sample(range(len(original_images)), 5)\n",
    "    for i, idx in enumerate(indices):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(original_images[idx], cmap='gray')\n",
    "        plt.title(f\"Original - {title}\")\n",
    "        plt.axis('off')\n",
    "        plt.subplot(2, 5, i+6)\n",
    "        plt.imshow(lbp_images[idx], cmap='gray')\n",
    "        plt.title(f\"LBP - {title}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_lbp(hole_images, lbp_hole_images, 'Hole')\n",
    "visualize_lbp(horizontal_images, lbp_horizontal_images, 'Horizontal')\n",
    "visualize_lbp(vertical_images, lbp_vertical_images, 'Vertical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2e1c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = joblib.load('best_fabric_defect_model_80-20_run3.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99904b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern\n",
    "import joblib\n",
    "\n",
    "def preprocess_image_from_path(image_path, radius=3, n_points=8 * 3):\n",
    "    img = load_image_from_path(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "    hist = calculate_lbp_histogram(lbp)\n",
    "\n",
    "    return hist, gray, lbp, img\n",
    "\n",
    "    \n",
    "def load_image_from_path(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Image not found at {image_path}\")\n",
    "    return img\n",
    "    \n",
    "def calculate_lbp_histogram(lbp_image, bins=256):\n",
    "    hist, _ = np.histogram(lbp_image.ravel(), bins=np.arange(0, bins + 1), density=True)\n",
    "    return hist\n",
    "    \n",
    "def find_defect_center(gray_img):\n",
    "    blur = cv2.GaussianBlur(gray_img, (5, 5), 0)\n",
    "    _, thresh = cv2.threshold(\n",
    "        blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n",
    "    )\n",
    "\n",
    "    contours, _ = cv2.findContours(\n",
    "        thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    if not contours:\n",
    "        return None, 0\n",
    "\n",
    "    largest = max(contours, key=cv2.contourArea)\n",
    "    area = cv2.contourArea(largest)\n",
    "\n",
    "    M = cv2.moments(largest)\n",
    "    if M[\"m00\"] == 0:\n",
    "        return None, area\n",
    "\n",
    "    cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "    return (cx, cy), area\n",
    "    \n",
    "def estimate_severity(defect_area, image_area):\n",
    "    ratio = defect_area / image_area\n",
    "\n",
    "    if ratio < 0.01:\n",
    "        return \"Low\"\n",
    "    elif ratio < 0.05:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "def predict_defect_from_path(image_path, classifier):\n",
    "    hist, gray, lbp, img = preprocess_image_from_path(image_path)\n",
    "    hist = hist.reshape(1, -1)\n",
    "\n",
    "    pred_class = classifier.predict(hist)[0]\n",
    "\n",
    "    if hasattr(classifier, \"predict_proba\"):\n",
    "        probabilities = classifier.predict_proba(hist)[0]\n",
    "    else:\n",
    "        scores = classifier.decision_function(hist)\n",
    "        probs = np.exp(scores - np.max(scores))\n",
    "        probabilities = probs / probs.sum()\n",
    "\n",
    "    class_confidence = {\n",
    "        cls: round(float(prob), 4)\n",
    "        for cls, prob in zip(classifier.classes_, probabilities)\n",
    "    }\n",
    "\n",
    "    center, defect_area = find_defect_center(gray)\n",
    "    severity = estimate_severity(\n",
    "        defect_area, gray.shape[0] * gray.shape[1]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"defect_type\": pred_class,\n",
    "        \"confidence_scores\": class_confidence,\n",
    "        \"defect_center_xy\": center,\n",
    "        \"severity\": severity\n",
    "    }\n",
    "\n",
    "classifier = joblib.load('best_fabric_defect_model_80-20_run3.pkl')\n",
    "\n",
    "# add your image path here\n",
    "IMAGE_PATH = \"/kaggle/input/hole-image/hole_image.jpg\"\n",
    "\n",
    "result = predict_defect_from_path(IMAGE_PATH, classifier)\n",
    "\n",
    "print(\"Defect Type      :\", result[\"defect_type\"])\n",
    "print(\"Confidence Scores:\", result[\"confidence_scores\"])\n",
    "print(\"Defect Center    :\", result[\"defect_center_xy\"])\n",
    "print(\"Severity         :\", result[\"severity\"])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
